{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>50921.0</td>\n",
       "      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>51382.8</td>\n",
       "      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>51844.6</td>\n",
       "      <td>https://insights.blackcoffer.com/what-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>52306.4</td>\n",
       "      <td>https://insights.blackcoffer.com/marketing-dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>52768.2</td>\n",
       "      <td>https://insights.blackcoffer.com/continued-dem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      URL_ID                                                URL\n",
       "0      123.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "4      432.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "..       ...                                                ...\n",
       "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...\n",
       "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...\n",
       "111  51844.6  https://insights.blackcoffer.com/what-are-the-...\n",
       "112  52306.4  https://insights.blackcoffer.com/marketing-dri...\n",
       "113  52768.2  https://insights.blackcoffer.com/continued-dem...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://insights.blackcoffer.com/ai-and-its-impact-on-the-fashion-industry/'\n",
    "article = Article(url, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download() \n",
    "article.parse() \n",
    "article.nlp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Title:\n",
      "AI and its impact on the Fashion Industry\n",
      "\n",
      "\n",
      "Article Text:\n",
      "If you were a fan of the 90’s film Clueless back in the day, then you’ll remember the protagonist, Cher Horowitz’s amazing virtual wardrobe. She used it to browse her clothing and choose a perfectly coordinated ensemble. This virtual application, which was just the brainchild of a writer wanting to make the protagonist look rich, fashionable, and ahead of her time, ignited a buzz and prospected having an automated style device to make everyday dress-up fun and engagingly time-saving.\n",
      "\n",
      "Times have changed and technological advancement today is transforming everything from probabilities to possibilities. We are in the era where, machines not just facilitate our tasks and demands but rather suggest, forecasts, and analyze thus making lives simpler and smarter.\n",
      "\n",
      "With the advent of technology, style suggestions are just a fraction of the big picture that AI has painted in the fashion industry today.\n",
      "\n",
      "What is AI?\n",
      "\n",
      "Artificial intelligence is the creation of computer programs capable of performing activities and solving issues that would normally need human intelligence. AI has surged across a variety of industries, with the potential to transform businesses through creative technologies and more effective operational processes.\n",
      "\n",
      "At first, AI automation did not appear to be an appealing tool for fashion leaders to use in an industry focused on creative ability and expression. However, as we enter the hyper-digital era, these apps have the potential to revolutionize enterprises and generate considerable industry growth when compared to competitors that use traditional approaches.\n",
      "\n",
      "Some of the most well-known brands in the business are now investing in algorithms that assist buyers to choose designs. A slew of AI-based start-ups is also assisting everyone from retailers to customers in removing the guesswork from the equation.\n",
      "\n",
      "Impact on fashion\n",
      "\n",
      "This article examines how artificial intelligence has impacted key areas of the fashion industry, as well as explores brands that have benefited from its use.\n",
      "\n",
      "AI in Apparel designing\n",
      "\n",
      "Fashion firms are utilizing technology to better understand client wants and produce better garments thanks to more sophisticated data collection.\n",
      "\n",
      "Tommy Hilfiger pioneered the “Reimagine Retail” project, which trains fashion designers with AI design skills in collaboration with IBM. As a result, fashion students could master a variety of technical skills such as natural language processing (NLP) or computer vision. Fashion students could learn from thousands of fashion-related photos using AI, which increased their inventiveness and shortened lead times for the fashion firm.\n",
      "\n",
      "AI in the Manufacturing process\n",
      "\n",
      "Fashion brands are now able to identify fast-changing fashion trends and get the latest fashion accessories to store shelves faster than the “traditional” fashion shop, thanks to AI and machine learning capabilities. As a result, prominent fashion brands such as Zara, Top Shop, and H&M can provide immediate gratification to retail customers by identifying seasonal trends and producing the appropriate quantity of the current items.\n",
      "\n",
      "AI in Logistics\n",
      "\n",
      "AI in inventory and supply chain management helps to speed up processes by optimizing routes and lowering logistics and shipping costs. Companies use AI to automate logistics and supply chain procedures for speedier delivery or to locate alternate routes for vehicles that have been detoured due to unanticipated situations like bad weather or road construction.\n",
      "\n",
      "Owing to lockdown, major fashion firms had to rethink their go-to-market strategy overnight, with actual brick-and-mortar stores closed and people staying away from shopping malls. Myntra finds itself in a unique position to assist them.\n",
      "\n",
      "Myntra moved its whole data infrastructure, including supply chain management, inventory, and website capabilities, to Microsoft Azure just before the pandemic. Apart from giving Myntra the flexibility to respond to demand spikes, Azure’s built-in Machine Learning technologies sped up the development of advanced analytics capabilities, allowing them to better understand their customers.\n",
      "\n",
      "AI in Fashion Retail\n",
      "\n",
      "In retail, AI and machine learning are also providing an automated solution to monitor customer activities while shopping and visualize their sentiments to learn what products they prefer to buy and what products they ignore.\n",
      "\n",
      "AI can also track traffic in retail stores or record consumer shopping experiences, with the option of receiving feedback on how their experience was while shopping at the store, allowing them to enhance their services.\n",
      "\n",
      "Uniqlo has AI-powered UMood kiosks that offer clients a selection of products and use neurotransmitters to assess their reaction to color and style. The kiosk then makes product recommendations based on each person’s reactions. Customers don’t even need to press a button for the system to know how they feel about each item; their brain signals are plenty.\n",
      "\n",
      "AI Fashion Stylist — Styling the Fashion Accessories\n",
      "\n",
      "Furthermore, AI in fashion is enabling each of us to find those elusive perfect garments that suit our body types and fashion preferences.\n",
      "\n",
      "These AI-enabled garments and ensembles are personalized to the user’s style, body type, colors, and current fashion trends, as well as different situations and weather.\n",
      "\n",
      "iLUK is an AI-based personal stylist that uses Computer Vision and 3D Reconstruction technology at its core to provide technology-based personal styling. It’s shaped like a pod that will be placed in a store.\n",
      "\n",
      "AI in Fast Fashion with Smart Mirror\n",
      "\n",
      "Similarly, a smart mirror driven by AI is being utilized by a company to streamline consumers’ shopping experiences by allowing them to virtually visualize how items would appear on them without having to put them on their bodies.\n",
      "\n",
      "The AI smart mirror with touch screen glasses is mounted in the changing room of retail stores and relays information on whether or not a person is inside. Customers can also use this mirror to try on other sizes and colors, as well as receive tailored mix-and-match alternatives to complete the appearance.\n",
      "\n",
      "Van Heusen designed a storage space that includes a “Virtual Trial” mirror that allows customers to view how clothes might appear on them by scanning the item’s barcode and stepping in front of the mirror while virtual clothing is projected onto their reflection.\n",
      "\n",
      "AI in Ecommerce\n",
      "\n",
      "In the same way that AI is revolutionizing retail fashion stores, AI is revolutionizing online purchasing and E-commerce. While browsing or searching for fashion goods on e-commerce sites, AI suggests additional items that are similar to what you’re looking for based on your color preferences, budget, and other factors. It analyses your search history data and suggests more relevant stuff you should look at.\n",
      "\n",
      "Amazon has undoubtedly transformed the online shopping experience with its AI-powered product suggestion engine. Amazon is implementing an AI-enabled fashion designer algorithm that can create clothing by mimicking the design styles of several popular garments and applying them to a new garment. The Echo Look fashion assistant, which uses machine learning to deliver personalized recommendations, is Amazon’s other use case.\n",
      "\n",
      "AI in Visual Search — To Find the Products Using Camera\n",
      "\n",
      "AI-based visual search technology is now employed by E-commerce stores to comprehend the content and context of these photographs and produce a list of related results. You can capture an object using your camera and then search for it online. Retailers can use AI-enabled computer vision-based visual search technology to propose thematically or aesthetically relevant items to customers in a way that would be difficult to do with only a word query.\n",
      "\n",
      "Neiman Marcus, a high-end department store, employs artificial intelligence to make it easier for shoppers to locate things. The Snap. Find. Shop. the app allows users to photograph items they encounter while out and about, and then search Neiman Marcus’ inventory for the same or a comparable item.\n",
      "\n",
      "AI in Fashion and Sustainability\n",
      "\n",
      "One of the most damaging businesses on the earth is the fashion industry. Artificial Intelligence can be used in conjunction with Machine Learning, Deep Learning, Natural Language Processing, Visual Recognition, and Data Analytics to reduce trend prediction errors and more precisely forecast patterns, leading to fewer garments being manufactured and subsequently underutilized.\n",
      "\n",
      "The H&M Group is using “Amplified Intelligence,” which combines analytics and AI with human intelligence.\n",
      "\n",
      "Using artificially intelligent technologies, H&M is enhancing its ability to recognize trends and organize logistics, as well as minimizing the frequency of discounted deals and large amounts of unsold goods.\n",
      "\n",
      "Though intelligence per se is artificial, nevertheless is likely to have an earnest impact, both positive and negative:\n",
      "\n",
      "The fashion dilemma\n",
      "\n",
      "Apparel manufacture is a labor-intensive industry in the fashion industry. AI-enabled machines and robots can perfectly stitch fabrics while also detecting fabric flaws and providing quality assurance to ensure that the actual design hues will match the new colors.\n",
      "\n",
      "In nations like Bangladesh, where the garment industry accounts for 80% of the GDP, this will have a significant influence on the labor force in the long run. It is already feeling the heat from these specialized AI-based devices, thus jeopardizing the jobs of breadwinners.\n",
      "\n",
      "AI should not be viewed as a rival, but rather as a collaborator. The cost and ethics of AI are currently preventing us from progressing. We must be careful not to use technology to increase inequity or exacerbate social injustice. We also need to find a balance and integrate humanity into the machines we’re constructing in the future.\n",
      "\n",
      "Virtual wonderland\n",
      "\n",
      "“We are being monitored and classified by AI in portions of our lives that were not previously watched,” says Sophie Hackford, a futurist and keynote speaker. She wonders if we’ve built the “wrong” internet. We created it intending to monetize our viewers in mind, rather than the dynamic knowledge-sharing area that Tim Berners-Lee envisioned at the start.” She believes that in the future, we will be much more selective in how we obtain information, and that “bots” would be critical in meeting our requirements. As a result, the gains will come at the expense of our privacy.\n",
      "\n",
      "As numerous as AI’s advantages are, it is impossible to ignore the difficult issues it brings. With everything being data-driven, there is a pressing need to establish boundaries to build a shared ecosystem that benefits both businesses and the general public.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Finding a wise balance between physical stores and online stores will continue to be a crucial issue in an industry where brick-and-mortar retail locations are still an important element of the sector’s approach to business.\n",
      "\n",
      "The usefulness of chatbots aimed at improving online and in-store product navigation shows significant promise for preserving customer attention and use in the near term. We expect consumers to become accustomed to these capabilities over time, and the field to become more competitive as AI becomes more broadly applied, as prominent brands set the tone with their usage of AI.\n",
      "\n",
      "It’s too early to tell how these AI applications will affect earnings and cost savings because prominent fashion firms are still in the early stages of AI implementation. However, there will be a learning curve as corporations figure out how consumers react to these innovation efforts, which could have a direct influence on sales.\n",
      "\n",
      "Blackcoffer Insights 33: Lakshman Upadhyay and Prabhlin Kaur Matta, Welingkar Institute of M D R, Mumbai\n",
      "\n",
      "\n",
      "Article Summary:\n",
      "Impact on fashionThis article examines how artificial intelligence has impacted key areas of the fashion industry, as well as explores brands that have benefited from its use.\n",
      "AI Fashion Stylist — Styling the Fashion AccessoriesFurthermore, AI in fashion is enabling each of us to find those elusive perfect garments that suit our body types and fashion preferences.\n",
      "AI in EcommerceIn the same way that AI is revolutionizing retail fashion stores, AI is revolutionizing online purchasing and E-commerce.\n",
      "AI in Fashion and SustainabilityOne of the most damaging businesses on the earth is the fashion industry.\n",
      "Though intelligence per se is artificial, nevertheless is likely to have an earnest impact, both positive and negative:The fashion dilemmaApparel manufacture is a labor-intensive industry in the fashion industry.\n",
      "\n",
      "\n",
      "Article Keywords:\n",
      "['impact', 'technology', 'learning', 'industry', 'fashion', 'retail', 'search', 'intelligence', 'shopping', 'stores', 'ai']\n"
     ]
    }
   ],
   "source": [
    "print(\"Article Title:\") \n",
    "print(article.title) #prints the title of the article\n",
    "print(\"\\n\") \n",
    "print(\"Article Text:\") \n",
    "print(article.text) #prints the entire text of the article\n",
    "print(\"\\n\") \n",
    "print(\"Article Summary:\") \n",
    "print(article.summary) #prints the summary of the article\n",
    "print(\"\\n\") \n",
    "print(\"Article Keywords:\")\n",
    "print(article.keywords) #prints the keywords of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    \n",
    "    url1 = url\n",
    "    article = Article(url1, language=\"en\")\n",
    "    \n",
    "    article.download() \n",
    "    article.parse() \n",
    "    article.nlp()\n",
    "    \n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(df)):\n",
    "#    df['URL_ID'][i] = get_text(df['URL'][i])\n",
    "    \n",
    "# Define a function to get text from a URL using your get_text function\n",
    "def get_text_from_url(url):\n",
    "    try:\n",
    "        return get_text(url)\n",
    "    except Exception as e:\n",
    "        # Handle exceptions or return a default value in case of errors\n",
    "        return 'Error: ' + str(e)\n",
    "\n",
    "# Apply the get_text_from_url function to the 'URL' column and create a new column 'Updated_URL_ID'\n",
    "df['Updated_URL_ID'] = df['URL'].apply(get_text_from_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Updated_URL_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>Telemedicine, the use of technology to diagnos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>The rise of e-health, or the use of electronic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>2020 was the year the world was ravaged by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>50921.0</td>\n",
       "      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n",
       "      <td>Before jumping on the topic I would like to gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>51382.8</td>\n",
       "      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n",
       "      <td>As the coronavirus spreads around the world an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>51844.6</td>\n",
       "      <td>https://insights.blackcoffer.com/what-are-the-...</td>\n",
       "      <td>From Alibaba to Ping An and Google to Ford, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>52306.4</td>\n",
       "      <td>https://insights.blackcoffer.com/marketing-dri...</td>\n",
       "      <td>When the British ruled India, many Indians acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>52768.2</td>\n",
       "      <td>https://insights.blackcoffer.com/continued-dem...</td>\n",
       "      <td>The business of business is no longer to do ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      URL_ID                                                URL  \\\n",
       "0      123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "4      432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "..       ...                                                ...   \n",
       "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...   \n",
       "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...   \n",
       "111  51844.6  https://insights.blackcoffer.com/what-are-the-...   \n",
       "112  52306.4  https://insights.blackcoffer.com/marketing-dri...   \n",
       "113  52768.2  https://insights.blackcoffer.com/continued-dem...   \n",
       "\n",
       "                                        Updated_URL_ID  \n",
       "0    Telemedicine, the use of technology to diagnos...  \n",
       "1    The rise of e-health, or the use of electronic...  \n",
       "2    2020 was the year the world was ravaged by the...  \n",
       "3    “More gains on quality, affordability and acce...  \n",
       "4    “More gains on quality, affordability and acce...  \n",
       "..                                                 ...  \n",
       "109  Before jumping on the topic I would like to gi...  \n",
       "110  As the coronavirus spreads around the world an...  \n",
       "111  From Alibaba to Ping An and Google to Ford, co...  \n",
       "112  When the British ruled India, many Indians acc...  \n",
       "113  The business of business is no longer to do ju...  \n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'URL_ID':'Text'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Updated_URL_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>Telemedicine, the use of technology to diagnos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>The rise of e-health, or the use of electronic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>2020 was the year the world was ravaged by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                                                URL  \\\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "\n",
       "                                      Updated_URL_ID  \n",
       "0  Telemedicine, the use of technology to diagnos...  \n",
       "1  The rise of e-health, or the use of electronic...  \n",
       "2  2020 was the year the world was ravaged by the...  \n",
       "3  “More gains on quality, affordability and acce...  \n",
       "4  “More gains on quality, affordability and acce...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     123.0\n",
      "1     321.0\n",
      "2    2345.0\n",
      "3    4321.0\n",
      "4     432.0\n",
      "Name: Text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Text'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Text                                                URL  \\\n",
      "0      123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "4      432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "..       ...                                                ...   \n",
      "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "111  51844.6  https://insights.blackcoffer.com/what-are-the-...   \n",
      "112  52306.4  https://insights.blackcoffer.com/marketing-dri...   \n",
      "113  52768.2  https://insights.blackcoffer.com/continued-dem...   \n",
      "\n",
      "                                        Updated_URL_ID  Transform_Text  \n",
      "0    Telemedicine, the use of technology to diagnos...           123.0  \n",
      "1    The rise of e-health, or the use of electronic...           321.0  \n",
      "2    2020 was the year the world was ravaged by the...          2345.0  \n",
      "3    “More gains on quality, affordability and acce...          4321.0  \n",
      "4    “More gains on quality, affordability and acce...           432.0  \n",
      "..                                                 ...             ...  \n",
      "109  Before jumping on the topic I would like to gi...         50921.0  \n",
      "110  As the coronavirus spreads around the world an...         51382.8  \n",
      "111  From Alibaba to Ping An and Google to Ford, co...         51844.6  \n",
      "112  When the British ruled India, many Indians acc...         52306.4  \n",
      "113  The business of business is no longer to do ju...         52768.2  \n",
      "\n",
      "[114 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amrit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to transform text\n",
    "def transform(text):\n",
    "    if isinstance(text, str):\n",
    "        review = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [word for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        return review\n",
    "    else:\n",
    "        return text  # Return the original value for non-string values\n",
    "\n",
    "# Apply the transform function to create a new column 'Transform_Text'\n",
    "df['Transform_Text'] = df['Text'].apply(transform)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Assuming you have already downloaded NLTK stopwords\n",
    "# If not, you can download them with: nltk.download('stopwords')\n",
    "\n",
    "# Function to transform text\n",
    "def transform(text):\n",
    "    if isinstance(text, str):\n",
    "        review = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [word for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        return review\n",
    "    else:\n",
    "        return text  # Return the original value for non-string values\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'Text' is the column with text data\n",
    "\n",
    "# Apply the transform function to create a new column 'Transform_Text'\n",
    "df['Transform_Text'] = df['Text'].apply(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count in each text row.\n",
    "\n",
    "df['word_counts'] = df['Transform_Text'].apply(lambda x: len(str(x).split()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Text                                                URL  \\\n",
      "0      123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "4      432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "..       ...                                                ...   \n",
      "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "111  51844.6  https://insights.blackcoffer.com/what-are-the-...   \n",
      "112  52306.4  https://insights.blackcoffer.com/marketing-dri...   \n",
      "113  52768.2  https://insights.blackcoffer.com/continued-dem...   \n",
      "\n",
      "                                        Updated_URL_ID  Transform_Text  \\\n",
      "0    Telemedicine, the use of technology to diagnos...           123.0   \n",
      "1    The rise of e-health, or the use of electronic...           321.0   \n",
      "2    2020 was the year the world was ravaged by the...          2345.0   \n",
      "3    “More gains on quality, affordability and acce...          4321.0   \n",
      "4    “More gains on quality, affordability and acce...           432.0   \n",
      "..                                                 ...             ...   \n",
      "109  Before jumping on the topic I would like to gi...         50921.0   \n",
      "110  As the coronavirus spreads around the world an...         51382.8   \n",
      "111  From Alibaba to Ping An and Google to Ford, co...         51844.6   \n",
      "112  When the British ruled India, many Indians acc...         52306.4   \n",
      "113  The business of business is no longer to do ju...         52768.2   \n",
      "\n",
      "     word_counts  Sentence_Count  \n",
      "0              1               0  \n",
      "1              1               0  \n",
      "2              1               0  \n",
      "3              1               0  \n",
      "4              1               0  \n",
      "..           ...             ...  \n",
      "109            1               0  \n",
      "110            1               0  \n",
      "111            1               0  \n",
      "112            1               0  \n",
      "113            1               0  \n",
      "\n",
      "[114 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to count sentences in text, handling non-string values\n",
    "def count_sentences(text):\n",
    "    if isinstance(text, str):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        return len(sentences)\n",
    "    else:\n",
    "        return 0  # Return 0 for non-string values\n",
    "\n",
    "# Create a sample DataFrame for illustration (replace with your actual data)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Apply the count_sentences function to create a new column 'Sentence_Count'\n",
    "df['Sentence_Count'] = df['Text'].apply(count_sentences)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Text                                                URL  \\\n",
      "0      123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "4      432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "..       ...                                                ...   \n",
      "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "111  51844.6  https://insights.blackcoffer.com/what-are-the-...   \n",
      "112  52306.4  https://insights.blackcoffer.com/marketing-dri...   \n",
      "113  52768.2  https://insights.blackcoffer.com/continued-dem...   \n",
      "\n",
      "                                        Updated_URL_ID  Transform_Text  \\\n",
      "0    Telemedicine, the use of technology to diagnos...           123.0   \n",
      "1    The rise of e-health, or the use of electronic...           321.0   \n",
      "2    2020 was the year the world was ravaged by the...          2345.0   \n",
      "3    “More gains on quality, affordability and acce...          4321.0   \n",
      "4    “More gains on quality, affordability and acce...           432.0   \n",
      "..                                                 ...             ...   \n",
      "109  Before jumping on the topic I would like to gi...         50921.0   \n",
      "110  As the coronavirus spreads around the world an...         51382.8   \n",
      "111  From Alibaba to Ping An and Google to Ford, co...         51844.6   \n",
      "112  When the British ruled India, many Indians acc...         52306.4   \n",
      "113  The business of business is no longer to do ju...         52768.2   \n",
      "\n",
      "     word_counts  Sentence_Count  average number of words per sentence  \n",
      "0              1               0                                   NaN  \n",
      "1              1               0                                   NaN  \n",
      "2              1               0                                   NaN  \n",
      "3              1               0                                   NaN  \n",
      "4              1               0                                   NaN  \n",
      "..           ...             ...                                   ...  \n",
      "109            1               0                                   NaN  \n",
      "110            1               0                                   NaN  \n",
      "111            1               0                                   NaN  \n",
      "112            1               0                                   NaN  \n",
      "113            1               0                                   NaN  \n",
      "\n",
      "[114 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to calculate average number of words per sentence, handling non-string values\n",
    "def calculate_average_words_per_sentence(text):\n",
    "    if isinstance(text, str):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        num_sentences = len(sentences)\n",
    "        if num_sentences > 0:\n",
    "            total_words = sum(len(nltk.word_tokenize(sentence)) for sentence in sentences)\n",
    "            return total_words / num_sentences\n",
    "        else:\n",
    "            return 0  # Handle case with no sentences\n",
    "    else:\n",
    "        return np.nan  # Return NaN for non-string values\n",
    "\n",
    "# Apply the calculate_average_words_per_sentence function to create a new column\n",
    "df['average number of words per sentence'] = df['Text'].apply(calculate_average_words_per_sentence)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Updated_URL_ID</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>Sentence_Count</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>Telemedicine, the use of technology to diagnos...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>The rise of e-health, or the use of electronic...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>2020 was the year the world was ravaged by the...</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2893.8</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-chatb...</td>\n",
       "      <td>The human race is known to come up with invent...</td>\n",
       "      <td>2893.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3355.6</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>Introduction\\n\\nThe phrase “e-health” refers t...</td>\n",
       "      <td>3355.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3817.4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-mark...</td>\n",
       "      <td>Marketing can be defined as an act of promotio...</td>\n",
       "      <td>3817.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4279.2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-advertise...</td>\n",
       "      <td>Advertising allows companies to differentiate ...</td>\n",
       "      <td>4279.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4741.0</td>\n",
       "      <td>https://insights.blackcoffer.com/negative-effe...</td>\n",
       "      <td>“Society can exist without Marketing, but Mark...</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                                                URL  \\\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "5  2893.8  https://insights.blackcoffer.com/rise-of-chatb...   \n",
       "6  3355.6  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "7  3817.4  https://insights.blackcoffer.com/how-does-mark...   \n",
       "8  4279.2  https://insights.blackcoffer.com/how-advertise...   \n",
       "9  4741.0  https://insights.blackcoffer.com/negative-effe...   \n",
       "\n",
       "                                      Updated_URL_ID  Transform_Text  \\\n",
       "0  Telemedicine, the use of technology to diagnos...           123.0   \n",
       "1  The rise of e-health, or the use of electronic...           321.0   \n",
       "2  2020 was the year the world was ravaged by the...          2345.0   \n",
       "3  “More gains on quality, affordability and acce...          4321.0   \n",
       "4  “More gains on quality, affordability and acce...           432.0   \n",
       "5  The human race is known to come up with invent...          2893.8   \n",
       "6  Introduction\\n\\nThe phrase “e-health” refers t...          3355.6   \n",
       "7  Marketing can be defined as an act of promotio...          3817.4   \n",
       "8  Advertising allows companies to differentiate ...          4279.2   \n",
       "9  “Society can exist without Marketing, but Mark...          4741.0   \n",
       "\n",
       "   word_counts  Sentence_Count  average number of words per sentence  \n",
       "0            1               0                                   NaN  \n",
       "1            1               0                                   NaN  \n",
       "2            1               0                                   NaN  \n",
       "3            1               0                                   NaN  \n",
       "4            1               0                                   NaN  \n",
       "5            1               0                                   NaN  \n",
       "6            1               0                                   NaN  \n",
       "7            1               0                                   NaN  \n",
       "8            1               0                                   NaN  \n",
       "9            1               0                                   NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(x):\n",
    "    s = x.split()\n",
    "    x = ''.join(s)\n",
    "    return len(x)      # counting the total number of characters in each text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Text                                                URL  \\\n",
      "0      123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
      "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "4      432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
      "..       ...                                                ...   \n",
      "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...   \n",
      "111  51844.6  https://insights.blackcoffer.com/what-are-the-...   \n",
      "112  52306.4  https://insights.blackcoffer.com/marketing-dri...   \n",
      "113  52768.2  https://insights.blackcoffer.com/continued-dem...   \n",
      "\n",
      "                                        Updated_URL_ID  Transform_Text  \\\n",
      "0    Telemedicine, the use of technology to diagnos...           123.0   \n",
      "1    The rise of e-health, or the use of electronic...           321.0   \n",
      "2    2020 was the year the world was ravaged by the...          2345.0   \n",
      "3    “More gains on quality, affordability and acce...          4321.0   \n",
      "4    “More gains on quality, affordability and acce...           432.0   \n",
      "..                                                 ...             ...   \n",
      "109  Before jumping on the topic I would like to gi...         50921.0   \n",
      "110  As the coronavirus spreads around the world an...         51382.8   \n",
      "111  From Alibaba to Ping An and Google to Ford, co...         51844.6   \n",
      "112  When the British ruled India, many Indians acc...         52306.4   \n",
      "113  The business of business is no longer to do ju...         52768.2   \n",
      "\n",
      "     word_counts  Sentence_Count  average number of words per sentence  \\\n",
      "0              1               0                                   NaN   \n",
      "1              1               0                                   NaN   \n",
      "2              1               0                                   NaN   \n",
      "3              1               0                                   NaN   \n",
      "4              1               0                                   NaN   \n",
      "..           ...             ...                                   ...   \n",
      "109            1               0                                   NaN   \n",
      "110            1               0                                   NaN   \n",
      "111            1               0                                   NaN   \n",
      "112            1               0                                   NaN   \n",
      "113            1               0                                   NaN   \n",
      "\n",
      "     Split_Text  \n",
      "0         123.0  \n",
      "1         321.0  \n",
      "2        2345.0  \n",
      "3        4321.0  \n",
      "4         432.0  \n",
      "..          ...  \n",
      "109     50921.0  \n",
      "110     51382.8  \n",
      "111     51844.6  \n",
      "112     52306.4  \n",
      "113     52768.2  \n",
      "\n",
      "[114 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to split text (if it's a string) or return the original value\n",
    "def split_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.split()\n",
    "    else:\n",
    "        return text  # Return the original value for non-string values\n",
    "\n",
    "# Apply the split_text function to create a new column 'Split_Text'\n",
    "df['Split_Text'] = df['Text'].apply(split_text)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-83e727b88282>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average word length'][i] = df['Split_Text'][i]/df['word_counts'][i]\n"
     ]
    }
   ],
   "source": [
    "df['average word length'] = np.nan\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['average word length'][i] = df['Split_Text'][i]/df['word_counts'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Updated_URL_ID</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>Sentence_Count</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>Split_Text</th>\n",
       "      <th>average word length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>Telemedicine, the use of technology to diagnos...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>The rise of e-health, or the use of electronic...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>2020 was the year the world was ravaged by the...</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>4321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                                                URL  \\\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "\n",
       "                                      Updated_URL_ID  Transform_Text  \\\n",
       "0  Telemedicine, the use of technology to diagnos...           123.0   \n",
       "1  The rise of e-health, or the use of electronic...           321.0   \n",
       "2  2020 was the year the world was ravaged by the...          2345.0   \n",
       "3  “More gains on quality, affordability and acce...          4321.0   \n",
       "4  “More gains on quality, affordability and acce...           432.0   \n",
       "\n",
       "   word_counts  Sentence_Count  average number of words per sentence  \\\n",
       "0            1               0                                   NaN   \n",
       "1            1               0                                   NaN   \n",
       "2            1               0                                   NaN   \n",
       "3            1               0                                   NaN   \n",
       "4            1               0                                   NaN   \n",
       "\n",
       "   Split_Text  average word length  \n",
       "0       123.0                123.0  \n",
       "1       321.0                321.0  \n",
       "2      2345.0               2345.0  \n",
       "3      4321.0               4321.0  \n",
       "4       432.0                432.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 5, 'e': 3, 'i': 4, 'a': 3, 'u': 1}\n",
      "['o', 'e', 'i', 'a', 'o', 'e', 'o', 'o', 'o', 'i', 'e', 'a', 'i', 'i', 'a', 'u']\n",
      "[5, 3, 4, 3, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "def syllable_count(x):\n",
    "    v = []\n",
    "    d = {}\n",
    "    for i in x:\n",
    "        if i in \"aeiou\":\n",
    "            v.append(i)\n",
    "            d[i] = d.get(i,0)+1     # checking purpose\n",
    "            \n",
    "    k = []\n",
    "    for i in d:\n",
    "        k.append(d[i])\n",
    "    print(d)\n",
    "    print(v)  \n",
    "    print(k)\n",
    "    print(np.sum(k))\n",
    "        \n",
    "    \n",
    "g = 'bore i am gone to london in england britian uk'\n",
    "\n",
    "syllable_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllable count for the text:\n",
      "0      Telemedicine, the use of technology to diagnos...\n",
      "1      The rise of e-health, or the use of electronic...\n",
      "2      2020 was the year the world was ravaged by the...\n",
      "3      “More gains on quality, affordability and acce...\n",
      "4      “More gains on quality, affordability and acce...\n",
      "                             ...                        \n",
      "109    Before jumping on the topic I would like to gi...\n",
      "110    As the coronavirus spreads around the world an...\n",
      "111    From Alibaba to Ping An and Google to Ford, co...\n",
      "112    When the British ruled India, many Indians acc...\n",
      "113    The business of business is no longer to do ju...\n",
      "Name: Updated_URL_ID, Length: 114, dtype: object\n",
      "\n",
      "is: 0\n",
      "Syllable count for the non-string input (123.45): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the syllable_count function\n",
    "def syllable_count(x):\n",
    "    if isinstance(x, str):  # Check if x is a string\n",
    "        v = []\n",
    "        d = {}\n",
    "        for i in x:\n",
    "            if i in \"aeiou\":\n",
    "                v.append(i)\n",
    "                d[i] = d.get(i, 0) + 1\n",
    "\n",
    "        k = []\n",
    "        for i in d:\n",
    "            k.append(d[i])\n",
    "\n",
    "        return np.sum(k)\n",
    "    else:\n",
    "        return 0  # Return 0 for non-string values\n",
    "\n",
    "# Example input: a string\n",
    "text_to_count = df['Updated_URL_ID']\n",
    "\n",
    "syllable_count_result = syllable_count(text_to_count)\n",
    "print(f'Syllable count for the text:\\n{text_to_count}\\n\\nis: {syllable_count_result}')\n",
    "\n",
    "# Example input: a non-string (float)\n",
    "#non_string_input = 123.45\n",
    "syllable_count_result = syllable_count(non_string_input)\n",
    "print(f'Syllable count for the non-string input ({non_string_input}): {syllable_count_result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['syllable count'] = df['Transform_Text'].apply(lambda x: syllable_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Updated_URL_ID</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>Sentence_Count</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>Split_Text</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>Telemedicine, the use of technology to diagnos...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>The rise of e-health, or the use of electronic...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>2020 was the year the world was ravaged by the...</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                                                URL  \\\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "\n",
       "                                      Updated_URL_ID  Transform_Text  \\\n",
       "0  Telemedicine, the use of technology to diagnos...           123.0   \n",
       "1  The rise of e-health, or the use of electronic...           321.0   \n",
       "2  2020 was the year the world was ravaged by the...          2345.0   \n",
       "3  “More gains on quality, affordability and acce...          4321.0   \n",
       "4  “More gains on quality, affordability and acce...           432.0   \n",
       "\n",
       "   word_counts  Sentence_Count  average number of words per sentence  \\\n",
       "0            1               0                                   NaN   \n",
       "1            1               0                                   NaN   \n",
       "2            1               0                                   NaN   \n",
       "3            1               0                                   NaN   \n",
       "4            1               0                                   NaN   \n",
       "\n",
       "   Split_Text  average word length  syllable count  \n",
       "0       123.0                123.0               0  \n",
       "1       321.0                321.0               0  \n",
       "2      2345.0               2345.0               0  \n",
       "3      4321.0               4321.0               0  \n",
       "4       432.0                432.0               0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_word_count(x):\n",
    "    if isinstance(x, str):\n",
    "        syllable = 'aeiou'\n",
    "        words = x.split()\n",
    "        complex_word_count = 0  # Initialize the count of complex words\n",
    "        \n",
    "        for word in words:\n",
    "            vowel_count = sum(1 for char in word if char in syllable)\n",
    "            if vowel_count >= 2:  # Check if the word has at least 2 vowels (complex word)\n",
    "                complex_word_count += 1\n",
    "\n",
    "        return complex_word_count\n",
    "    else:\n",
    "        return 0  # Return 0 for non-string inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Updated_URL_ID</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>Sentence_Count</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>Split_Text</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>Telemedicine, the use of technology to diagnos...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>The rise of e-health, or the use of electronic...</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "      <td>2020 was the year the world was ravaged by the...</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "      <td>“More gains on quality, affordability and acce...</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                                                URL  \\\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...   \n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem...   \n",
       "\n",
       "                                      Updated_URL_ID  Transform_Text  \\\n",
       "0  Telemedicine, the use of technology to diagnos...           123.0   \n",
       "1  The rise of e-health, or the use of electronic...           321.0   \n",
       "2  2020 was the year the world was ravaged by the...          2345.0   \n",
       "3  “More gains on quality, affordability and acce...          4321.0   \n",
       "4  “More gains on quality, affordability and acce...           432.0   \n",
       "\n",
       "   word_counts  Sentence_Count  average number of words per sentence  \\\n",
       "0            1               0                                   NaN   \n",
       "1            1               0                                   NaN   \n",
       "2            1               0                                   NaN   \n",
       "3            1               0                                   NaN   \n",
       "4            1               0                                   NaN   \n",
       "\n",
       "   Split_Text  average word length  syllable count  complex_count  \n",
       "0       123.0                123.0               0              0  \n",
       "1       321.0                321.0               0              0  \n",
       "2      2345.0               2345.0               0              0  \n",
       "3      4321.0               4321.0               0              0  \n",
       "4       432.0                432.0               0              0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complex_count'] = np.nan\n",
    "\n",
    "df['complex_count'] = df['Transform_Text'].apply(lambda x: complex_word_count(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-20124e95e30d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Calculate sentence length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentence length'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Calculate average sentence length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \"\"\"\n\u001b[1;32m-> 1272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \"\"\"\n\u001b[0;32m   1356\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"after_tok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# Assume 'word_counts' and 'complex_count' columns are already present in df\n",
    "\n",
    "# Initialize columns with NaN values if not already present\n",
    "if 'sentence length' not in df.columns:\n",
    "    df['sentence length'] = np.nan\n",
    "if 'Average Sentence Length' not in df.columns:\n",
    "    df['Average Sentence Length'] = np.nan\n",
    "if 'Percentage of Complex words' not in df.columns:\n",
    "    df['Percentage of Complex words'] = np.nan\n",
    "if 'Fog Index' not in df.columns:\n",
    "    df['Fog Index'] = np.nan\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    # Calculate sentence length\n",
    "    df.loc[i, 'sentence length'] = len(nltk.sent_tokenize(df['Text'][i]))\n",
    "    \n",
    "    # Calculate average sentence length\n",
    "    df.loc[i, 'Average Sentence Length'] = df['word_counts'][i] / df['sentence length'][i]\n",
    "    \n",
    "    # Calculate percentage of complex words\n",
    "    df.loc[i, 'Percentage of Complex words'] = df['complex_count'][i] / df['word_counts'][i]\n",
    "    \n",
    "    # Calculate Fog Index\n",
    "    df.loc[i, 'Fog Index'] = 0.4 * (df['Average Sentence Length'][i] + df['Percentage of Complex words'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv('sentiment dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = sentiment[['Word','Negative','Positive']]\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = ['ZYGOTIC','BAD','DONE','EXCELLENT','WORSE']\n",
    "\n",
    "negative = 0\n",
    "positive = 0\n",
    "\n",
    "for i in dfs['Word']:\n",
    "    if i in f:\n",
    "        if dfs[dfs['Word']==i].Negative.any() == True:\n",
    "            negative += 1\n",
    "        if dfs[dfs['Word']==i].Positive.any() == True:                # CHECKING\n",
    "            positive += 1\n",
    "            \n",
    "print(negative),\n",
    "print(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.dropna()\n",
    "dfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'the good man'\n",
    "w.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['word_lower'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "        dfs['word_lower'][i] = dfs['Word'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50742,len(dfs)):\n",
    "        dfs['word_lower'][i] = dfs['Word'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['word_lower'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the positive score for text.\n",
    "\n",
    "def positive(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    positive = 0\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Positive.any() == True:\n",
    "                positive += 1\n",
    "            \n",
    "    return positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['positive_score'][i] = positive(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_word(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    positive_word = []\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Positive.any() == True:   # checking which words are positive\n",
    "                positive_word.append(i)\n",
    "            \n",
    "    print(positive_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_word'] = np.nan\n",
    "\n",
    "for i in range(1):\n",
    "    df['positive_word'][i] = positive_word(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('positive_word',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    negative = 0\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Negative.any() == True:\n",
    "                negative += 1\n",
    "            \n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negative_score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['negative_score'][i] = negative_score(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity Score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['Polarity Score'][i] = (df['positive_score'][i]-df['negative_score'][i])/ ((df['positive_score'][i] + df['negative_score'][i]) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(df['Transform_Text'][1])\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(df['Transform_Text'][1]).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subjectivity'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['subjectivity'][i] = TextBlob(df['Transform_Text'][i]).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'he is the my father'\n",
    "y = nlp(x)\n",
    "\n",
    "for noun in y.noun_chunks:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('he is the my father')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'PRON':\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(df['Text'][1])\n",
    "tok = []\n",
    "for token in doc:\n",
    "    if token.pos_ == 'PRON':\n",
    "        tok.append(token)\n",
    "        \n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'][1] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    doc = nlp(df['Text'][i])\n",
    "    tok = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON':\n",
    "            tok.append(token)\n",
    "        \n",
    "    df['PERSONAL PRONOUNS'][i] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df[['URL','positive_score','negative_score','Polarity Score','subjectivity','Average Sentence Length','Percentage of Complex words',\n",
    "            'Fog Index','average number of words per sentence','complex_count','word_counts','syllable count','PERSONAL PRONOUNS','average word length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Output Data Structure.xlsx\"\n",
    "\n",
    "submit.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
